gfrom pyspark.sql import SparkSession
from pyspark.sql.functions import from_unixtime

# Create a Spark session
spark = SparkSession.builder.appName("example").getOrCreate()

# Sample data
data = [(1686268800000,), (1686355200000,), (1686441600000,)]
columns = ["timestamp_column"]

# Create a DataFrame
df = spark.createDataFrame(data, columns)

# Convert timestamp to date format
df_casted = df.withColumn("date_column", from_unixtime(df["timestamp_column"] / 1000).cast("date"))

# Show the result
df_casted.show()
