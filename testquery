from pyspark.sql import SparkSession
from pyspark.sql.functions import min, max

# Create a Spark session
spark = SparkSession.builder.appName("date_min_max").getOrCreate()

# Assuming your DataFrame is named 'df' and has a 'date_column'
min_max_dates = df.agg(min("date_column").alias("min_date"), max("date_column").alias("max_date")).collect()

# Extract the min and max dates from the result
min_date = min_max_dates[0]["min_date"]
max_date = min_max_dates[0]["max_date"]

print("Min Date:", min_date)
print("Max Date:", max_date)
