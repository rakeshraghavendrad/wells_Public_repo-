from pyspark.sql import SparkSession
from pyspark.sql.functions import col, expr

# Create a Spark session
spark = SparkSession.builder.master("local").appName("MinMaxDate").getOrCreate()

# Sample data
data = [("2023-01-01",), ("2023-06-01",), ("2023-03-15",), ("2023-09-30",)]
df = spark.createDataFrame(data, ["date_column"])

# Finding min and max date using expr
result = df.agg(
    expr("min(date_column)").alias("min_date"),
    expr("max(date_column)").alias("max_date")
)

# Show the result
result.show()
