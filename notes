from pyspark.sql import SparkSession

# Create a Spark session
spark = SparkSession.builder.appName("ConvertColumnsToString").getOrCreate()

# Sample data
data = [
    (1, 1.0),
    (2, 3.5),
    (3, 3.0),
    (4, 5.1),
    (5, 5.0)
]

# Create DataFrame
df = spark.createDataFrame(data, ["Column1", "Column2"])

# Convert all columns to string type
string_df = df.selectExpr(*[f"cast({col} as string) as {col}" for col in df.columns])

# Show the DataFrame with columns converted to string
string_df.printSchema()
string_df.show()












# Select 'id' and the comparison expressions
non_matching_columns = df_combined.select("id", *comparison_exprs)

# Filter out rows where all compared columns match (i.e., all are NULL)
non_matching_columns_filtered = non_matching_columns.filter(
    " OR ".join([f"{col}_non_matching IS NOT NULL" for col in columns_to_compare])
)

non_matching_columns_filtered.show()
