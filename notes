

from pyspark.sql import SparkSession
from pyspark.sql.functions import col

# Create a SparkSession
spark = SparkSession.builder \
    .appName("CustomerSegmentAnalysis") \
    .getOrCreate()

# Assuming your DataFrame is named 'df' with columns 'Cust_num', 'date', and 'segment'

# Filter for customers in segment 1 in January 2023
segment_1_jan_2023 = df.filter((col("segment") == 1) & (col("date") == "202301"))

# Filter for customers who moved to segments 3 or 4 in April 2024
segment_3_4_apr_2024 = df.filter((col("segment").isin([3, 4])) & (col("date") == "202304"))

# Join the DataFrames for each month to track customer movement
joined_df = segment_1_jan_2023.alias("jan"). \
    join(df.alias("feb"), ["Cust_num"], "left_outer"). \
    join(df.alias("mar"), ["Cust_num"], "left_outer"). \
    join(segment_3_4_apr_2024.alias("apr"), ["Cust_num"], "left_outer"). \
    select("jan.Cust_num", 
           "jan.segment", col("feb.segment").alias("feb_segment"), 
           col("mar.segment").alias("mar_segment"), 
           col("apr.segment").alias("apr_segment"))

# Display the DataFrame
joined_df.show()

# Stop the SparkSession
spark.stop()from pyspark.sql import SparkSession
from pyspark.sql import functions as F
from pyspark.sql.window import Window

# Create a Spark session
spark = SparkSession.builder.appName("segment_classification").getOrCreate()

# Sample data
data = [
    (12345, None, 202301, 0, 0, 0, 0, 0, 0, 1),
    (None, 12345, 202302, 4, 0, 0, 0, 0, 0, 2),
    (None, 12345, 202303, 0, 0, 0, 0, 0, 1, 2),
    (None, 12345, 202304, 0, 0, 3, 1, 0, 0, 3),
    (None, 12345, 202305, 0, 1, 0, 0, 0, 1, 3),
    (None, 12345, 202306, 0, 0, 1, 1, 1, 0, 3),
    (None, 12345, 202307, 1, 1, 7, 1, 0, 0, 4),
    (None, 12345, 202308, 1, 1, 2, 1, 1, 0, 4)
]

# Define schema
schema = ["cust_num_seg", "cust_num", "date", "feature1", "feature2", "feature3", "feature4", "feature5", "feature6", "segment"]

# Create a DataFrame
df = spark.createDataFrame(data, schema=schema)

# Define a window specification based on cust_num
window_spec = Window.partitionBy("cust_num").orderBy("date").rangeBetween(Window.unboundedPreceding, Window.currentRow)

# Count the number of features used for each cust_num
feature_columns = ["feature1", "feature2", "feature3", "feature4", "feature5", "feature6"]
for col in feature_columns:
    df = df.withColumn(col + "_count", F.sum(col).over(window_spec))

# Determine the segment based on the feature counts
df = df.withColumn(
    "segment",
    F.when(df["feature1_count"] >= 1, "seg2")
    .when(df["feature1_count"] + df["feature2_count"] >= 2, "seg3")
    .when(F.array([df[col + "_count"] for col in feature_columns]).sum() >= 4, "seg4")
    .otherwise(None)
)

# Drop the temporary count columns
df = df.drop(*[col + "_count" for col in feature_columns])

# Show the result
df.show(truncate=False)
