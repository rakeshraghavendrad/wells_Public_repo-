https://arxiv.org/pdf/2107.00396

Dataset generation : no real images were used 
-> The entire dataset was synthetically generated using mock templates and artificial data.
-> The creators used publicly available document templates from sources like Wikimedia Commons.
-> Artificial faces were generated using tools like Generated Photos, which produce realistic-looking faces without using real peopleâ€™s data.

so total 1000 dataset was created post this 
1.1 Scanning the Documents:
->Used high-resolution scanners to create sharp, clear images.
->Generated 2,000 scanned images (each document scanned twice with slight variations).
1.2 Photographing the Documents:
->Used various lighting conditions and angles to take photos.
->Ensured that documents were photographed both flat and at slight tilts.
->Captured 1,000 photographs to add diversity.
1.3 Video Recording:
->Recorded 1,000 video clips.
->Videos captured documents being moved, tilted, and rotated.
-> Each clip demonstrated dynamic perspectives.

Pertubations : 

2.1 Augmentation Techniques:
-> Lighting Variations: Introduced bright, dim, and uneven lighting conditions.
-> Perspective Distortion: Applied slight rotations and skews.
-> Motion Blur: Simulated shaky camera captures.
-> Background Variability: Placed documents against different backgrounds (tables, textured surfaces).

2.2 Resolution Adjustments:
-> Captured documents at various resolutions to mimic both high-quality and low-quality captures.
-> Some images were deliberately compressed to reflect mobile phone camera limitations.


https://arxiv.org/html/2408.01690v2#bib.bib2

1. Template Generation Using Image Diffusion Models from hugging face : 

-> Employed image diffusion models, such as Stable Diffusion, to remove existing texts and photos from sample ID images.
-> Masked customizable regions (e.g., name, photo areas) and prompted the model to inpaint these areas, generating clean templates.
-> For complex documents, iterative refinement with adjusted masks ensured high-quality template generation.

2. Fraud Pattern Simulation
-> To enhance the dataset's utility in fraud detection research, several fraudulent scenarios were synthetically generated:
-> Face Morphing: Blended two facial images to create a morphed portrait, simulating advanced identity fraud techniques.
-> Portrait Substitution: Replaced the original portrait with a disqualified or mismatched photo.
-> Text-Field Replacement: Altered specific textual fields (e.g., name, date of birth) with inconsistencies in font and formatting.
-> Mixed Fraud: Combined multiple fraud types within a single document.
-> Inpaint and Rewrite: Used inpainting techniques to modify specific fields without altering the overall layout.
-> Crop and Replace: Swapped sections between different IDs to simulate tampering.


https://arxiv.org/pdf/2409.12318

Participant Recruitment and Consent : 
-> A total of 3,991 participants were recruited for the study.
-> Each participant provided informed consent, with the process approved by an Institutional Review Board (IRB), ensuring ethical standards were upheld.
-> Participants were instructed to use their mobile devices to capture images of their government-issued identification cards and a self-portrait (selfie).
->

https://arxiv.org/pdf/2503.01085

Dataset used : 
 MIDV-500 Dataset
-> it offers real-world variability in:
-> Lighting conditions
-> Background settings
-> Document orientations
-> Device diversity (videos recorded using different mobile devices)

2.2 Preprocessing the Dataset:
Frame Extraction:
-> Extracted frames from each video clip at 10 frames per second (fps).
-> Focused on the first 3 seconds of each video to ensure consistency.
-> This resulted in approximately 15,000 image frames.
Image Annotation:
-> The MIDV-500 dataset already contains annotations specifying:
-> Document boundaries
-> Text fields
-> Photo areas
-> These annotations were utilized directly for training without additional modification.
-> The model demonstrated a high IoU (>0.8) and accuracy (>0.75) when detecting document boundaries.
