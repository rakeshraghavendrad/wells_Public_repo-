from pyspark.sql.functions import sum as spark_sum

total_count = comparison_df.count()
match_count = comparison_df.filter(col("is_match") == True).count()
match_percentage = (match_count / total_count) * 100

print(f"Total Rows: {total_count}")
print(f"Matching Rows: {match_count}")
print(f"Matching Percentage: {match_percentage:.2f}%")


import matplotlib.pyplot as plt

# Collect data to driver
match_stats = comparison_df.groupBy("is_match").count().collect()
match_dict = {row["is_match"]: row["count"] for row in match_stats}

matching_count = match_dict.get(True, 0)
non_matching_count = match_dict.get(False, 0)

# Plotting
labels = ['Matching', 'Non-Matching']
counts = [matching_count, non_matching_count]

plt.figure(figsize=(8, 6))
plt.bar(labels, counts, color=['green', 'red'])
plt.xlabel('Comparison Result')
plt.ylabel('Count')
plt.title('Comparison of DataFrames')
plt.show()
