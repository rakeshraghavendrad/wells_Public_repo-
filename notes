Using a combination of Jaccard, Cosine, and Levenshtein similarity scores offers a robust method for address matching because each metric addresses specific strengths and limitations of the other measures. Here’s a breakdown of the advantages and how each score complements the others:

1. Jaccard Similarity:

	•	Advantage: Jaccard similarity is ideal for capturing exact token matches (e.g., words or phrases) between two addresses. It calculates the ratio of shared tokens to total unique tokens, focusing on token overlap.
	•	Disadvantage: It can be overly strict and sensitive to variations, penalizing differences in tokens that might still be contextually similar. For example, “Main Street” vs. “Main St” would have a lower score due to token variation.
	•	How Other Scores Compensate:
	•	Cosine similarity accounts for partial matches and is more forgiving with variations in token frequency, which helps address minor token differences.
	•	Levenshtein similarity allows for character-level differences, such as abbreviations or minor typos (e.g., “St.” vs. “Street”), making it a good supplement when Jaccard is too strict.

2. Cosine Similarity:

	•	Advantage: Cosine similarity measures the angle between vectorized text representations, focusing on the frequency of terms rather than exact matches. This allows it to capture similarity even when token sequences differ, making it useful when addresses have additional descriptive terms (e.g., “123 Main Street Apt 4” vs. “Main St Apt 4”).
	•	Disadvantage: Cosine similarity might score dissimilar addresses too highly if they share some common terms, potentially giving partial matches a higher score than desired.
	•	How Other Scores Compensate:
	•	Jaccard similarity reduces the effect of purely frequency-based matches, as it only considers exact token overlap, preventing unrelated addresses from scoring too highly.
	•	Levenshtein similarity fine-tunes the matching by handling minor typos and character-level differences, where cosine might struggle.

3. Levenshtein Similarity:

	•	Advantage: Levenshtein similarity measures character-level edits (insertions, deletions, substitutions) needed to transform one address into another, making it useful for handling spelling mistakes, abbreviations, or minor formatting differences.
	•	Disadvantage: It can be overly sensitive to length differences and is less effective for capturing context if the structure or order of words is very different.
	•	How Other Scores Compensate:
	•	Jaccard similarity reinforces token-level matching, ensuring that minor character edits don’t overly inflate similarity scores for otherwise dissimilar addresses.
	•	Cosine similarity captures frequency and context by focusing on word vectors, adding robustness for partially matching terms that Levenshtein might miss due to strict edit-distance calculations.

Example Scenario: Address Matching Robustness

Let’s say we are comparing two addresses:
	•	Address 1: "123 Main Street Apt 4"
	•	Address 2: "Apt 4, 123 Main St"

	1.	Jaccard: This score would capture the token overlap between these addresses, focusing on shared terms like "Main", "Street", and "Apt". However, due to the tokenization, “Street” vs. “St” might lower the score slightly.
	2.	Cosine: This score would account for the frequency and vector representation of words. Since both addresses mention "Main" and "Apt", cosine similarity would provide a reasonable match, even though "Street" is abbreviated in Address 2. Cosine allows the model to capture similarity despite the order of words.
	3.	Levenshtein: This score would capture minor character edits between terms, such as "Street" and "St", and the reordering of terms (like moving "Apt 4" to the beginning of Address 2). It ensures small typos or abbreviations don’t overly penalize the similarity score.

With weights like 0.333 for each, these scores collectively yield a balanced measure. By combining all three:
	•	Token-level precision from Jaccard is retained,
	•	Term frequency context from Cosine provides flexibility,
	•	Character-level tolerance from Levenshtein corrects for minor formatting or spelling variations.

This combination offers a more nuanced and robust match, better reflecting similarity across diverse address formats than any individual score alone.






# Levenshtein similarity function using textdistance
def levenshtein_similarity(str1, str2):
    # Normalize Levenshtein distance to similarity between 0 and 1
    max_len = max(len(str1), len(str2))
    if max_len == 0:
        return 1.0  # If both strings are empty, they are identical
    return 1 - (textdistance.levenshtein.distance(str1, str2) / max_len)
