from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split

# Encode the target column
df['profile_match_encoded'] = df['profile_match'].map({'Profile_matched': 1, 'Profile_notmatched': 0}).fillna(0)

# Label encoding for categorical features (for simplicity, you can use one-hot encoding as well)
df['first_name_encoded'] = df['first_name_db1'].astype('category').cat.codes
df['second_name_encoded'] = df['second_name_db1'].astype('category').cat.codes

# Define features (X) and target (y)
X = df[['first_name_encoded', 'second_name_encoded']]
y = df['profile_match_encoded']

# Split data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Train Random Forest model
rf = RandomForestClassifier(n_estimators=100, random_state=42)
rf.fit(X_train, y_train)

# Get feature importance
importances = rf.feature_importances_
feature_names = X.columns
feature_importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': importances})

# Sort by importance
feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)
print(feature_importance_df)
