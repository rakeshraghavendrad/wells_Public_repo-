
from pymongo import MongoClient
from datetime import datetime
import pytz

# Connect to MongoDB
client = MongoClient("your_mongodb_connection_string")
db = client["your_database_name"]
collection = db["your_collection_name"]

# Define start and end dates (in UTC)
start_date = datetime(2025, 2, 20, 0, 0, 0, tzinfo=pytz.UTC)
end_date = datetime(2025, 2, 21, 0, 0, 0, tzinfo=pytz.UTC)

# Query filter using UTC datetime
query = {
    "CreatedDate": {
        "$gte": start_date,
        "$lt": end_date
    }
}

# Execute query
results = collection.find(query)

# Print results (optional)
for doc in results:
    print(doc)


import pytz

# Define timezone objects
utc = pytz.utc
pst = pytz.timezone('US/Pacific')

# First, ensure your column is timezone-aware in UTC
df['create_dt'] = pd.to_datetime(df['create_dt'], utc=True)

# Convert to PST and store in a new column
df['create_dt_pst'] = df['create_dt'].dt.tz_convert(pst)











# Define start date as one day before end date
start_date = end_date - timedelta(days=1)

print("Start Date (UTC):", start_date)
print("End Date (UTC):", end_date)

# Connect to MongoDB
client = MongoClient('mongodb://IDPF_PROD_BI:W6%40CFu1Skg8N71a@...')

# Create filter using UTC timestamps
filter = {
    'eventName': 'abx',
    'requestHeader': 'dfv',
    'createdDate': {
        '$gte': start_date,
        '$lt': end_date
    }
}





2025-06-02 07:00:00 to 2025-06-03 07:00:00 (UTC)

start = 2025-06-02 00:00:00 PST = 2025-06-02 07:00:00 UTC  
end   = 2025-06-03 00:00:00 PST = 2025-06-03 07:00:00 UTCimport pytz
import pandas as pd

# Define Pacific Time zone
pst = pytz.timezone("America/Los_Angeles")

# Localize the datetime to Pacific Time
start = pst.localize(pd.to_datetime('2025-06-03 00:00:00'))
end = pst.localize(pd.to_datetime('2025-06-04 00:00:00'))




1. 
{
  "supplementalData.DocumentRiskConditions.DQL_Default_Results.DQL_Classification_IssuerName": "Cheap"
}

{
  "supplementalData.DocumentRiskConditions.DQL_Default_Results": {
    "$elemMatch": {
      "DQL_Classification_IssuerName": "Cheap"
    }
  }
}





Entity Matching Project (Jan–Feb):
Led the development of a robust solution for generating similarity scores for address fields in the Entity Matching project. Successfully completed the module and ensured a seamless handover to the Predictive Analytics team prior to the team transition.

2. Transition to GenAI Initiatives:
	•	Gained deep understanding of vendor model evaluation frameworks, particularly focusing on fraud detection mechanisms involving providers like Mitek.
	•	Conducted in-depth research on model robustness, resulting in the design and development of a modular framework for testing model performance under image perturbations.
	•	Implemented and validated multiple image perturbation techniques including blur, grayscale, block movement (2%), and rotation—demonstrating model behavior under diverse input conditions.

3. AID Integration and Evaluation:
	•	Successfully completed the end-to-end integration of the AID system with MongoDB using PyMongo, enabling seamless access and querying of image metadata collections.
	•	Integrated and tested the AID API via Postman, facilitating the evaluation of synthetic images. Identified a few inconsistencies in image verification and initiated clarification with the AID support team.

4. Research Contribution:
Currently contributing to an upcoming micropaper focused on Noise Awareness in AI Models, with submission and publication in progress.
