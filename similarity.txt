I have referred to several research papers and articles to develop a robust approach for calculating Address Similarity Scores by combining multiple similarity measures. The key references include:

“Similarity Measures for Title Matching” – This paper provides a comprehensive overview of various similarity scores used for string matching.
“Matching Scientific Article Titles using Cosine Similarity and Jaccard Similarity Algorithm” – This study demonstrates that a combined approach using multiple similarity metrics results in improved accuracy.
“Combining Approximate String Matching Algorithms and Term Frequency in the Detection of Plagiarism” – This research highlights the effectiveness of hybrid algorithms in detecting textual similarity in everyday language.
String Similarity Methods: Pros & Cons, and Choosing the Best Approach – This article discusses how combining multiple similarity measures enhances performance.
Building on insights from these sources, I formulated an approach that combines Levenshtein Distance, Cosine Similarity, and Jaccard Similarity, assigning equal weights (0.333) to each metric. This method effectively balances character-level, word-level, and semantic similarity, resulting in a more generalized and reliable similarity score.


https://ishwaryasriraman.medium.com/string-similarity-methods-pros-cons-and-choosing-the-best-approach-1e9dc2ce5936



Combination of Scores (Balanced Approach)
By calculating a weighted average of Jaccard, Cosine, and Levenshtein similarity scores, we achieve a balance that cancels out each metric’s disadvantages:

Levenshtein handles typos and minor variations (which Jaccard and Cosine struggle with).
Cosine captures frequency-based word importance (which Levenshtein ignores).
Jaccard ensures token overlap is accounted for (which Cosine does partially and Levenshtein doesn’t).
This holistic approach ensures a well-rounded similarity evaluation, making it robust across various text types and structures.


import textdistance
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity

# Fixed Jaccard Similarity (returns decimal values)
def jaccard_sim(str1, str2):
    return textdistance.jaccard.normalized_similarity(str1, str2)

# Fixed Cosine Similarity (returns decimal values)
def cosine_sim(str1, str2):
    vectorizer = TfidfVectorizer().fit_transform([str1, str2])  
    vectors = vectorizer.toarray()
    return cosine_similarity([vectors[0]], [vectors[1]])[0, 0]

# Levenshtein Similarity (already works correctly)
def levenshtein_similarity(str1, str2):
    max_len = max(len(str1), len(str2))
    return 1 - (textdistance.levenshtein.distance(str1, str2) / max_len) if max_len > 0 else 1.0

# Address Similarity Score (now all components return decimal values)
def address_similarity_score(address1, address2):
    jaccard_score = jaccard_sim(address1, address2)
    cosine_score = cosine_sim(address1, address2)
    levenshtein_score = levenshtein_similarity(address1, address2)
    
    combined_score = (jaccard_score + cosine_score + levenshtein_score) / 3
    return combined_score
