from pyspark.sql import SparkSession
from pyspark.sql.functions import col

# Create a Spark session
spark = SparkSession.builder.appName("IPLoginComparison").getOrCreate()

# Assuming you have a DataFrame named 'your_table'
# Replace 'your_table' with the actual name of your DataFrame

# Select the rows where firstiplogin and secondiplogin are the same
same_ip_count = your_table.filter(col("firstiplogin") == col("secondiplogin")).groupBy("Custnum").count()

# Show the result
same_ip_count.show()
